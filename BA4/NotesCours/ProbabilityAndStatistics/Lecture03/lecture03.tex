% !TeX program = lualatex
% Using VimTeX, you need to reload the plugin (\lx) after having saved the document in order to use LuaLaTeX (thanks to the line above)

\documentclass[a4paper]{article}

% Expanded on 2023-02-28 at 13:21:32.

\usepackage{../../style}

\title{ProbaStats}
\author{Joachim Favre}
\date{Mardi 28 f√©vrier 2023}

\begin{document}
\maketitle

\lecture{3}{2023-02-28}{Overwatch characters doing algebra}{
\begin{itemize}[left=0pt]
    \item Definition of sample spaces.
    \item Definition of event spaces, and explanation of their properties.
    \item Definition of probability distributions, and explanation of their properties.
    \item Explanation of the inclusion-exclusion formula.
    \item Definition of probability spaces.
    \item Definition of equiprobable events, and some examples.
\end{itemize}

}

\section{Probability}
\subsection{Probability space}
\begin{parag}{Goal}
    The goal of this part is to make the definition of a probability space. This will first require the definition of three other objects.
\end{parag}

\begin{parag}{Definition: Sample space}
    The \important{sample space} of an experiment, noted $\Omega$, is the set of all possible events that can take place in it.

    It can be finite, countable or uncountable.
\end{parag}

\begin{parag}{Definition: Event space}
    An \important{event space} (or sigma-algebra, or \textit{tribu} in French) $\mathcal{F}$ is a set of subsets of $\Omega$ such that:
    \begin{itemize}
        \item $\mathcal{F}$ is nonempty.
        \item If $A \in \mathcal{F}$, then $A^C \in \mathcal{F}$ (where $A^C = \Omega \setminus A$ is the complement of $A$).
        \item If $\left\{A_i\right\}_{i=1}^{\infty}$ are all elements of $\mathcal{F}$, then: 
        \[\bigcup_{i=1}^{\infty} A_i \in\mathcal{F}\]
    \end{itemize}

    Each element of $A \in \mathcal{F}$, $A \subseteq \Omega$, is named an \important{event}.

    \begin{subparag}{Remark}
        This basically represents the set of interesting events from $\Omega$. 

        Typically, if $\Omega$ is countable, we can always take $\mathcal{F}$ to be its power set (the set of subsets of $\Omega$). This will always be the biggest sigma-algebra we can define, and another will be a subset of it. In other words, any question we can ask ourselves about the experiment can always be translated into an element of the power set.

        However, if $\Omega$ is not countable, then, in general, we cannot just take the power set of $\Omega$. For instance, the power set of $\left[0, 1\right]$ is not a sigma algebra. 
    \end{subparag}
\end{parag}

\begin{parag}{Properties}
    An event space $\mathcal{F}$ has the following properties, thanks to its axioms:
    \begin{itemize}
        \item $\displaystyle \bigcup_{i=1}^{n} A_i \in F$
        \item $\displaystyle \Omega \in \mathcal{F}, \o \in \mathcal{F}$
        \item $\displaystyle A \cap B \in \mathcal{F}, A \setminus B \in \mathcal{F}, A\ \Delta\ B \in \mathcal{F}$ where $\Delta$ is the ``xor'' of the sets (the symmetric difference).
        \item $\displaystyle \bigcap_{i=1}^{n} A_i \in F$
    \end{itemize}
    
    \begin{subparag}{Proof 1}
        To prove the first property, we can just take $A_{n+1} = A_{n+2} = \ldots$ and set them to be equal to $A_n$. Then, we only need to apply the third axiom.
    \end{subparag}

    \begin{subparag}{Proof 2}
        If $\mathcal{F}$ is non-empty, then it has an element $A$. By the second axiom, $A^C \in \mathcal{F}$. However, by the third property:
        \[A \cup A^C = \Omega \in \mathcal{F}\]

        Finally, by the second axiom: 
        \[\Omega^C = \o \in \mathcal{F}\]
    \end{subparag}

    \begin{subparag}{Proof 2 and 3}
        We can write those properties using unions and complements, and they are thus yielded by the previous axioms and properties.
    \end{subparag}
\end{parag}

\begin{parag}{Example 1}
    Let us consider the sample space of throwing a coin, $\Omega = \left\{H, T\right\}$. Then, we can pick either of the two event space: 
    \[\mathcal{F}_1 = \left\{\left\{H, T\right\}, \o\right\}, \mathspace \mathcal{F}_2 = \left\{\left\{H, T\right\}, \left\{H\right\}, \left\{T\right\}, \o\right\}\]
    
    Naturally, only the second one is useful.

    \begin{subparag}{Remark}
        In general, the following is always a valid sigma algebra: 
        \[\left\{\Omega, \o\right\}\]
        
    \end{subparag}
\end{parag}

\begin{parag}{Example 2}
    Let us consider an event where we throw a red die and a green die. Also let $A$ be the event that the red die shows a 4 and $B$ the event that the sum is odd.

    Then, $A \cap B$ is the event that the red die shows a 4 and that the sum is odd.
\end{parag}

\begin{parag}{Definition: Probability distribution}
    A \important{probability distribution} $\prob: \mathcal{F} \mapsto \left[0, 1\right]$ assigns a probability to each element of the event space $\mathcal{F}$, with the following properties:
    \begin{enumerate}
        \item For all $A \in \mathcal{F}$, then $0 \leq \prob\left(A\right) \leq 1$.
        \item $\prob\left(\Omega\right) = 1$.
        \item If $\left\{A_i\right\}_{i=1}^{\infty}$ are pairwise disjoint (meaning, for $i \neq j$, then $A_i \cap A_j = \o$), then: 
        \[\prob\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} \prob\left(A_i\right)\]
    \end{enumerate}

    The fact that two events are disjoint means that they cannot happen at the same time. The third axiom thus means that, if some events cannot happen at the same time, the probability that any of them happen is just the sum of probabilities.
\end{parag}

\begin{parag}{Properties}
    Let $A, B, \left\{A_i\right\}_{i=1}^{\infty}$ be events of some event space. Then:
    \begin{enumerate}
        \item $\prob\left(\o\right) = 0$
        \item $\prob\left(A^C\right) = 1 - \prob\left(A\right)$
        \item $\prob\left(A \cup B\right) = \prob\left(A\right) + \prob\left(B\right) - \prob\left(A \cap B\right)$.
        \item If $A \cap B = \o$, then $\prob\left(A \cup B\right) = P\left(A\right) + P\left(B\right)$.
        \item If $A \subset B$, then $P\left(A\right) \leq P\left(B\right)$ and $P\left(B \setminus A\right) = P\left(B\right) - P\left(A\right)$.
        \item $\displaystyle \prob\left(\bigcup_{i=1}^{\infty} A_i\right) \leq \sum_{i=1}^{\infty} \prob\left(A_i\right)$, known as Boole's inequality or the union bound.
        \item If $A_1 \subset A_2 \subset \ldots$, then $\displaystyle \lim_{n \to \infty} \prob\left(A_n\right) = \prob\left(\bigcup_{i=1}^{\infty} A_i\right)$
        \item If $A_1 \supset A_2 \supset \ldots$, then $\displaystyle \lim_{n \to \infty} \prob\left(A_n\right) = \prob\left(\bigcap_{i=1}^{\infty} A_i\right)$
    \end{enumerate}
    
    The third property is very important. It means that if add the two probabilities, we will have counted their intersection twice. Also, the union bound is used very often (using it is typically much easier than using the inclusion-exclusion formula (which comes right after)).
\end{parag}

\begin{parag}{Inclusion-exclusion formula}
    If $A_1, \ldots, A_n$ are events of some event space, then: 
    \[\prob\left(\bigcup_{i=1}^n A_i\right) = \sum_{r=1}^{n} \left(-1\right)^{r+1} \sum_{1 \leq i_1 < \ldots < i_r \leq n}^{} \prob\left(A_{i_1} \cap \ldots \cap A_{i_r}\right)\]

    This formula has $2^n - 1$ terms.
    
    \begin{subparag}{Example}
        For instance, for $n = 2$: 
        \[\prob\left(A_1 \cup A_2\right) = \prob\left(A_1\right) + \prob\left(A_2\right) - \prob\left(A_1 \cap A_2\right)\]
        
        Or, for $n =3$: 
        \autoeq{\prob\left(A_1 \cup A_2 \cup A_3\right) = \prob\left(A_1\right) + \prob\left(A_2\right) + \prob\left(A_3\right) \fakeequal - \prob\left(A_1 \cap A_2\right) - \prob\left(A_1 \cap A_3\right) - \prob\left(A_2 \cap A_3\right) \fakeequal + \prob\left(A_1 \cap A_2 \cap A_3\right)}
    \end{subparag}
    
    \begin{subparag}{Remark}
        This formula can typically be found back by drawing a Venn diagram, and being careful on what parts of the diagram we counted, and how many times.

        Also, note that we should almost never use this formula when $n$ is big (say more than 4), since it quickly becomes unmanageable. 
    \end{subparag}

    \begin{subparag}{Proof}
        This proof can be done by induction.
    \end{subparag}
    
\end{parag}

\begin{parag}{Example 1}
    We want to know the probability of getting at least one 6 when rolling three fair dice. 

    Let $A_i$ be the event there is a 6 on die $i$; we want to compute $\prob\left(A_1 \cup A_2 \cup A_3\right)$. However, by symmetry, $\prob\left(A_i\right) = \frac{1}{6}$, $\prob\left(A_i \cap A_j\right) = \frac{1}{6^2}$ (the probability that die $i$ and die $j$ yield both a 6 is $\frac{1}{6^2}$), and $\prob\left(A_1 \cap A_2 \cap A_3\right) = \frac{1}{6^3}$. Thus, by the inclusion-exclusion formula: 
    \[\prob\left(A_1 \cup A_2 \cup A_3\right) = 3\cdot \frac{1}{6} - 3\cdot \frac{1}{6^2} + \frac{1}{6^3} = \frac{91}{216}\]

    \begin{subparag}{Remark}
        In this case, it is better to consider the complement: the event that no die rolls a 6. Since the die are independent, we simply get that: 
        \[\prob\left(B^C\right) = \frac{5^3}{6^3} \implies \prob\left(B\right) = 1 - \prob\left(B^C\right) = 1 - \frac{5^3}{6^3} = \frac{91}{216}\]
    \end{subparag}
\end{parag}

\begin{parag}{Example 2}
    We want to compute the probability that a random number from 1 to 1000 is divisible by 2, 3 or 5.

    Let $D_i$ be the property that the number is divisible by $i$. We thus want to compute $\prob\left(D_2 \cup D_3 \cup D_5\right)$. Also, we notice that $\prob\left(D_i\right) = \left\lfloor \frac{1000}{i} \right\rfloor  / 1000$ since there are $\left\lfloor \frac{1000}{i} \right\rfloor$ numbers divisible by $i$ from 1 to 1000. We can apply the inclusion-exclusion formula: 
    \autoeq{\prob\left(D_2 \cup D_3 \cup D_5\right) = \prob\left(D_2\right) + \prob\left(D_3\right) + \prob\left(D_5\right) - \prob\left(D_2 \cap D_3\right) \fakeequal - \prob\left(D_2 \cap D_5\right) - \prob\left(D_3 \cap D_5\right) + \prob\left(D_2 \cap D_3 \cap D_5\right) = \prob\left(D_2\right) + \prob\left(D_3\right) + \prob\left(D_5\right) - \prob\left(D_6\right) - \prob\left(D_{10}\right) - \prob\left(D_{15}\right) + \prob\left(D_{30}\right) = \frac{500 + 333 + 200 - 166 - 100 - 66 + 33}{1000} = \frac{367}{500} = 0.734}
\end{parag}


\begin{parag}{Definition: Probability space}
    A \important{probability space} $\left(\Omega, \mathcal{F}, \prob\right)$ is a mathematical object associated with a random experiment, where $\Omega$ is its sample space, $\mathcal{F}$ is its event space, and $\prob : \mathcal{F} \mapsto \left[0, 1\right]$ is its probability distribution.

    \begin{subparag}{Remark}
        Any random experiment is modelled by such a probability space. In exams (and exercises), it is important to always give the sample space and the event space.

        In other words, this definition is really important.
    \end{subparag}
\end{parag}

\subsection{Equiprobable events}
\begin{parag}{Equiprobable events}
    If it is finite, we typically try to take the sample space $\Omega$ so that each of its elements $\omega \in \Omega$ is equiprobable, i.e: 
    \[\prob\left(\omega\right) = \frac{1}{\left|\Omega\right|}, \mathspace \forall \omega \in \Omega\]

    In this case, we simply have: 
    \[\prob\left(A\right) = \frac{\left|A\right|}{\left|\Omega\right|}, \mathspace \forall A \subseteq \Omega\]
\end{parag}

\begin{parag}{Example 1}
    Let us consider that we throw two fair dice, one red and one green. The sample space of this experiment is:
    \[\Omega = \left\{11, 12, \ldots, 16, 21, 22, \ldots, 66\right\}\]
    where the first letter is the outcome of the red dice and the second one is the outcome of the green one. We can take $\mathcal{F}$ to be the power set of $\Omega$.

    The event that at least a die outputs a 1 is given by: 
    \[A = \left\{11, 12, 13, 14, 15, 16, 21, 31, 41, 51, 61\right\} \subseteq \mathcal{F}\]
    
    Then, the probability that $A$ takes place is given by: 
    \[\prob\left(A\right) = \frac{\left|A\right|}{\left|\Omega\right|} = \frac{2\cdot 6 - 1}{6^2} = \frac{11}{36}\]
\end{parag}

\begin{parag}{Example 2}
    We wonder what is the probability that all $n$ people in a room have a different birthday.

    The sample space can be written as $\Omega = \left\{1, \ldots, 365\right\}^{n}$, where each of those possibilities have probability $365^{-n}$. We seek the probability of the following event: 
    \[A = \left\{\left(i_1, \ldots, i_n\right) \suchthat i_1 \neq i_2 \ldots \neq i_n\right\}\]
    
    We can see that $\left|A\right| = \frac{365!}{\left(365 - n\right)!}$, since there are 365 possibilities for the first person, 364 for the second one, and so on. This gives us that: 
    \[\prob\left(A\right) = \frac{\left|A\right|}{\left|\Omega\right|} = \frac{\frac{365!}{\left(365 - n\right)!}}{365^n} = \frac{365!}{\left(365 - n\right)! 365^n}\]
    
    This curve decays very rapidly. This may seem a bit counterintuitve, hence it is named the birthday paradox.
    \imagehere[0.5]{BirthdayParadox.png}
\end{parag}

\begin{parag}{Example 3}
    We throw three dice, and we let $T_i$ be the event of the sum being equal to $i$. We wonder if $T_9$ or $T_{10}$ is more likely (meaning is it more like to have a sum of 9 or 10).

    Our sample space is given by: 
    \[\Omega = \left\{\left(r, s, t\right) \suchthat r, s, t = 1, \ldots, 6\right\} \implies \left|\Omega\right| = 6^3\]
    
    We can notice that: 
    \[9 = 6 + 2 + 1 = 5 + 3 + 1 = 5 + 2 + 2 = 4 + 4 + 1 = 4 + 3 + 2 = 3 + 3 + 3\]
    \[10 = 6 + 3 + 1 = 6 + 2 + 2 = 5 + 4 + 1 = 5 + 3 + 2 = 4 + 4 + 2 = 4 + 4 + 3\]
    
    There is the same number of ways to sum to 9 and to sum to 10. However, the die are distinguishable, meaning that there is exactly one way to make $3 + 3 + 3$, $3$ to make $4 + 4 + 1$ and $3!$ to make $5 + 3 + 1$. In other words, we need to be careful in our computations. If we do them correctly, we get: 
    \[\left|T_9\right| = 25, \mathspace \left|T_{10}\right| = 27\]
    
    We thus get that $T_{10}$ is more probable.
\end{parag}



\end{document}
